/**
 * AI Executor Service for OpenRouter.ai Integration
 *
 * This service handles the execution of prompts using OpenRouter.ai,
 * transforming the MCP server from returning prompts to returning actual results.
 */
import { AIConfig } from '../config/ai-config.js';
export interface AIExecutionResult {
    /** The AI-generated response content */
    content: string;
    /** Model used for generation */
    model: string;
    /** Token usage information */
    usage?: {
        promptTokens: number;
        completionTokens: number;
        totalTokens: number;
    };
    /** Execution metadata */
    metadata: {
        executionTime: number;
        cached: boolean;
        retryCount: number;
        timestamp: string;
    };
}
export interface AIExecutionError extends Error {
    code: string;
    retryable: boolean;
    originalError?: unknown;
}
/**
 * AI Executor Service Class
 */
export declare class AIExecutor {
    private client;
    private config;
    private cache;
    constructor(config?: AIConfig);
    /**
     * Initialize OpenAI client for OpenRouter
     */
    private initializeClient;
    /**
     * Check if AI execution is available
     */
    isAvailable(): boolean;
    /**
     * Reload configuration if environment variables have changed
     */
    private reloadConfigIfNeeded;
    /**
     * Execute a prompt and return the AI response
     */
    executePrompt(prompt: string, options?: {
        model?: string;
        temperature?: number;
        maxTokens?: number;
        systemPrompt?: string;
    }): Promise<AIExecutionResult>;
    /**
     * Execute a structured prompt that expects JSON response
     */
    executeStructuredPrompt<T = any>(prompt: string, schema?: any, options?: {
        model?: string;
        temperature?: number;
        maxTokens?: number;
        systemPrompt?: string;
    }): Promise<{
        data: T;
        raw: AIExecutionResult;
    }>;
    /**
     * Extract JSON content from AI response, handling markdown code blocks
     */
    private extractJsonFromResponse;
    /**
     * Generate cache key for a prompt execution
     */
    private generateCacheKey;
    /**
     * Get cached result if available and not expired
     */
    private getCachedResult;
    /**
     * Cache a result
     */
    private setCachedResult;
    /**
     * Clean up expired cache entries
     */
    private cleanupCache;
    /**
     * Create a standardized AI execution error
     */
    private createError;
    /**
     * Get current configuration
     */
    getConfig(): AIConfig;
    /**
     * Update configuration
     */
    updateConfig(newConfig: Partial<AIConfig>): void;
    /**
     * Clear cache
     */
    clearCache(): void;
    /**
     * Get cache statistics
     */
    getCacheStats(): {
        size: number;
        hitRate: number;
    };
}
/**
 * Get or create the global AI executor instance
 */
export declare function getAIExecutor(): AIExecutor;
/**
 * Reset the global AI executor (useful for testing)
 */
export declare function resetAIExecutor(): void;
//# sourceMappingURL=ai-executor.d.ts.map